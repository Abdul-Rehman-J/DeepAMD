# -*- coding: utf-8 -*-
"""DeepMalwareDetect.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vRNOgpZpyas5qWOMX7S7F2LwHrDDCnuZ

```
# This is formatted as code
```

***DeepDetectMalware***
"""

from google.colab import drive
drive.mount('/content/drive')

import numpy as np
import pandas as pd
import seaborn as sns
from pandas import read_csv
from numpy import set_printoptions
from keras.utils import np_utils

from sklearn.decomposition import PCA
from sklearn import preprocessing
from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier
from sklearn.naive_bayes import GaussianNB
from sklearn import metrics
from sklearn.feature_selection import SelectKBest,f_classif
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
from sklearn.metrics import confusion_matrix,roc_curve,roc_auc_score,cohen_kappa_score,f1_score,recall_score,precision_score,accuracy_score
import matplotlib.pyplot as plt
import keras
from keras.layers import LSTM, GRU, Embedding, Dense
from keras.activations import sigmoid, softmax, tanh
from keras.optimizers import adam, sgd
from keras.models import Model, Sequential
from sklearn.preprocessing import LabelEncoder, LabelBinarizer, MultiLabelBinarizer
from keras.layers import Dense, Activation
from keras.utils import to_categorical
from keras.models import load_model
import tensorflow as tf
import tensorflow.keras as keras
from keras.layers import Dense, Dropout, LSTM, Embedding

# data = pd.read_csv('/content/drive/My Drive/Normalizedataset.csv', sep=',')
data = pd.read_csv('/content/drive/My Drive/DynamicLayerDataset.csv')
data.head()

np.unique(data['<Family>'])

# data=data.drop(['BinaryType','category'], axis=1)
# data.head()

X=data.iloc[:,:-1] 
Y=data.iloc[:,-1]
cols = X.columns

#for conventaional algotirhms

encoder = LabelEncoder()
encoder.fit(data.iloc[:,-1])
data['family'] = encoder.transform(data.iloc[:,-1])
# print(transformed_label)
# cols = data.columns

#for Deep Learning algotirhms
# encode class values as integers
encoder = LabelEncoder()
encoder.fit(Y)
encoded_Y = encoder.transform(Y)
# convert integers to dummy variables (i.e. one hot encoded)
Y = np_utils.to_categorical(encoded_Y)

min_max_scaler = preprocessing.MinMaxScaler()
X = min_max_scaler.fit_transform(X)
X = pd.DataFrame(X,columns=cols)
X.head()

print (np.unique(Y))

# #Using Pearson Correlation for feature selection
# plt.figure(figsize=(12,10))
# cor = data.corr()
# sns.heatmap(cor, cmap=plt.cm.Reds)
# plt.show()

# #Correlation with output variable
# cor_target = abs(cor["class"])
# #Selecting highly correlated features
# relevant_features = cor_target[cor_target>0.4]
# relevant_features

# # feature extraction
# test = SelectKBest(score_func=f_classif, k=10)
# fit = test.fit(X, Y)
# # summarize scores
# set_printoptions(precision=3)
# print(fit.scores_)
# features = fit.transform(X)
# # summarize selected features
# print(features[0:5,:])

X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size=0.80, random_state=1000)
print(X_train.shape)
print(Y_train.shape)
print(X_test.shape)
print(Y_test.shape)

np.unique(Y)

"""**Decision Tree**"""

from sklearn.tree import DecisionTreeClassifier

# Create Decision Tree classifer object
clf = DecisionTreeClassifier()

# Train Decision Tree Classifer
clf = clf.fit(X_train,Y_train)

#Predict the response for test dataset
y_pred = clf.predict(X_test)

# predictions = tree.predict_proba(X_test)
from sklearn.metrics import classification_report, confusion_matrix
print(confusion_matrix(Y_test, y_pred))
print(classification_report(Y_test, y_pred))

print("Accuracy:",metrics.accuracy_score(Y_test, y_pred))
print("F1-Score:",metrics.f1_score(Y_test, y_pred,average='weighted'))
print("Recall:",metrics.recall_score(Y_test, y_pred,average='weighted'))
print("Precision:",metrics.precision_score(Y_test, y_pred,average='weighted'))
# print ("Roc Curve",metrics.roc_auc_score(Y_test, predict_proba[:,1]))

"""**Naive Bayes**"""

clf = GaussianNB()
clf = clf.fit(X_train,Y_train)

#Predict the response for test dataset
y_pred = clf.predict(X_test)


# predictions = tree.predict_proba(X_test)
from sklearn.metrics import classification_report, confusion_matrix
print(confusion_matrix(Y_test, y_pred))
print(classification_report(Y_test, y_pred))


print("Accuracy:",metrics.accuracy_score(Y_test, y_pred))
print("F1-Score:",metrics.f1_score(Y_test, y_pred,average='weighted'))
print("Recall:",metrics.recall_score(Y_test, y_pred,average='weighted'))
print("Precision:",metrics.precision_score(Y_test, y_pred,average='weighted'))
# print ("Roc Curve",metrics.roc_auc_score(Y_test, predict_proba[:,1]))

"""**SVM**"""

from sklearn import svm

clf = svm.SVC()
clf.fit(X_train, Y_train)


#Predict the response for test dataset
y_pred = clf.predict(X_test)


# predictions = tree.predict_proba(X_test)
from sklearn.metrics import classification_report, confusion_matrix
print(confusion_matrix(Y_test, y_pred))
print(classification_report(Y_test, y_pred))

print("Accuracy:",metrics.accuracy_score(Y_test, y_pred))
print("F1-Score:",metrics.f1_score(Y_test, y_pred,average='weighted'))
print("Recall:",metrics.recall_score(Y_test, y_pred,average='weighted'))
print("Precision:",metrics.precision_score(Y_test, y_pred,average='weighted'))
# print ("Roc Curve",metrics.roc_auc_score(Y_test, predict_proba[:,1]))

"""**MLP**"""

from sklearn.neural_network import MLPClassifier

clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1)
clf.fit(X_train, Y_train)
MLPClassifier(alpha=1e-05, hidden_layer_sizes=(5, 2), random_state=1,solver='lbfgs')

#Predict the response for test dataset
y_pred = clf.predict(X_test)


# predictions = tree.predict_proba(X_test)
from sklearn.metrics import classification_report, confusion_matrix
print(confusion_matrix(Y_test, y_pred))
print(classification_report(Y_test, y_pred))


print("Accuracy:",metrics.accuracy_score(Y_test, y_pred))
print("F1-Score:",metrics.f1_score(Y_test, y_pred,average='weighted'))
print("Recall:",metrics.recall_score(Y_test, y_pred,average='weighted'))
print("Precision:",metrics.precision_score(Y_test, y_pred,average='weighted'))
# print ("Roc Curve",metrics.roc_auc_score(Y_test, predict_proba[:,1]))

"""**Deep Learning**"""

model=Sequential()
model.add(Dense(130, input_dim=918, activation='relu'))
model.add(Dropout(0.35))
model.add(Dense(120, activation='relu'))
model.add(Dropout(0.35))
model.add(Dense(100, activation='relu'))
model.add(Dropout(0.35))
model.add(Dense(39, activation='softmax'))
# Compile model
model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

history=model.fit(x=X_train,y=Y_train,validation_split=0.20,batch_size=6,epochs=50,verbose=1)

print(history.history.keys())
# summarize history for accuracy
plt.plot(history.history['acc'],marker='+')
plt.plot(history.history['val_acc'],color='cyan',marker='*')
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()
# summarize history for loss
plt.plot(history.history['loss'],marker='+')
plt.plot(history.history['val_loss'],color='cyan',marker='*')
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

# evaluate the model
train_acc = model.evaluate(X_train, Y_train, verbose=0)
test_acc = model.evaluate(X_test, Y_test, verbose=0)

print("Train Accuracy is",train_acc)
print("Test Accuracy is",test_acc)

val_loss, val_acc = model.evaluate(X_test, Y_test)
print("Validation Accuracy is",val_acc)
print("Validation Loss is",val_loss)

# predict probabilities for test set
yhat_probs = model.predict(X_test, verbose=0)
# predict crisp classes for test set
yhat_classes = model.predict_classes(X_test, verbose=0)
print(yhat_classes)
print(Y_test)
# reduce to 1d array
# yhat_probs = yhat_probs[:, 0]
# yhat_classes = yhat_classes[:, 0]

import numpy as np
Y_test=np.argmax(Y_test, axis=1)
Y_test[1]

# accuracy: (tp + tn) / (p + n)
accuracy = accuracy_score(Y_test, yhat_classes)
print('Accuracy: %f' % accuracy)
# precision tp / (tp + fp)
precision = precision_score(Y_test, yhat_classes,average='weighted')
print('Precision: %f' % precision)
# recall: tp / (tp + fn)
recall = recall_score(Y_test, yhat_classes,average='weighted')
print('Recall: %f' % recall)
# f1: 2 tp / (2 tp + fp + fn)
f1 = f1_score(Y_test, yhat_classes,average='weighted')
print('F1 score: %f' % f1)
# kappa
kappa = cohen_kappa_score(Y_test, yhat_classes)
print('Cohens kappa: %f' % kappa)
# ROC AUC
auc = roc_auc_score(Y_test, yhat_probs.round())
print('ROC AUC: %f' % auc)

ns_probs=[0 for _ in range(len(Y_test))]
# # keep probabilities for the positive outcome only
# lr_probs = yhat_probs[:, 1]
# calculate scores
ns_auc = roc_auc_score(Y_test, ns_probs)
lr_auc = roc_auc_score(Y_test, yhat_probs)

# summarize scores
print('Abnormal: ROC AUC=%.3f' % (ns_auc))
print('Normal: ROC AUC=%.3f' % (lr_auc))

# calculate roc curves

ns_fpr, ns_tpr, _ = roc_curve(Y_test, ns_probs)
lr_fpr, lr_tpr, _ = roc_curve(Y_test, yhat_probs)
# plot the roc curve for the model
plt.plot(ns_fpr, ns_tpr, linestyle='--', label=ns_auc)
plt.plot(lr_fpr, lr_tpr, marker='*', label=lr_auc)
# axis labels
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
# show the legend
plt.legend()
# show the plot
plt.show()

# confusion matrix
cf_matrix = confusion_matrix(Y_test, yhat_classes)
print(cf_matrix)
df_cm = pd.DataFrame(cf_matrix, 
  index = ['adware', 'ransomware', 'scareware', 'smsMalware'],
  columns = ['adware', 'ransomware', 'scareware', 'smsMalware'])
# sns.heatmap(df_cm, annot=True)

cmap = sns.cubehelix_palette(light=1, as_cmap=True)
# sns.heatmap(df_cm/np.sum(df_cm), annot=True, fmt='.2%', cmap='Blues') #for better look divide by 2
sns.heatmap(df_cm/np.sum(df_cm)*100, annot=True, vmin=0.0, vmax=100.0, fmt='.2f', cmap=cmap)

model.save('adsd.model')

new_model = tf.keras.models.load_model('adsd.model')
predictions = new_model.predict(X_test)
print(predictions)

print(np.argmax(predictions[0]))

